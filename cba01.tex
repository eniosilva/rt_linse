\documentclass[conference,harvard,brazil,english]{sbatex}
\usepackage[latin1]{inputenc}
\usepackage{graphicx,url}
\usepackage{ae}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{subfigure}
\usepackage{graphicx,color}

%% Declaração de Operadores Matemáticos
\DeclareMathOperator{\NB}{NB}
\DeclareMathOperator{\WB}{WB}
\DeclareMathOperator{\UP}{UP}
\DeclareMathOperator{\LSF}{LSF}
\DeclareMathOperator{\CB}{CB}
\DeclareMathOperator{\exci}{exc}
\DeclareMathOperator{\vo}{v}
\DeclareMathOperator{\nv}{nv}
\DeclareMathOperator{\transp}{^T}

% --------------------------------------------------
%
% Para compilar este exemplo use a seqüência de comandos:
%
%     latex cba
%     bibtex cba
%     latex cba
%     latex cba
%
% Para gerar um arquivo Postscript (.ps):
%
%     dvips -t a4 cba
%
% Para gerar um arquivo Portable Document Format (.pdf):
%
%     dvips -Ppdf -t a4 cba
%     ps2pdf -dMaxSubsetPct=100 -dSubsetFonts=true -dEmbedAllFonts=true -dCompatibilityLevel=1.2 -sPAPERSIZE=a4 cba.ps
%

% --------------------------------------------------
%  Estes comandos são necessários apenas para a
%  a geração deste artigo exemplo. Eles não fazem
%  parte do estilo SBATeX.
% --------------------------------------------------
\makeatletter
\def\verbatim@font{\normalfont\ttfamily\footnotesize}
\makeatother
\usepackage{amsmath}
% --------------------------------------------------


\begin{document}

% CABEÇALHO

\title{Extensão Artificial de Largura de Banda Aplicada a Sistemas de Reconhecimento Automático de Fala em Redes de Telefonia}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% O processo de revisao do CBA 2014 sera DOUBLE BLIND, portanto NAO inclua
% autores na versão que será submetida para revisão
%
% http://www.intechopen.com/books/modern-speech-recognition-approaches-with-case-studies/voiceconet-a-collaborative-framework-for-speech-based-computer-accessibility-with-a-case-study-for-b
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\author{Ênio dos Santos Silva}{enio@linse.ufsc.br}
\author{Ênio dos Santos Silva, Rui Seara}{enio@linse.ufsc.br, seara@linse.ufsc.br}
\address{LINSE -- Laboratório de Circuitos e Processamento de Sinais \\
Departamento de Engenharia Elétrica - Universidade Federal de Santa Catarina (UFSC)\\
Florianópolis, SC - Brasil}

%\author{Rui Seara}{seara@linse.ufsc.br}

\twocolumn[

\maketitle

\selectlanguage{english}
\begin{abstract}
This work presents a new strategy for the implementation of automatic speech recognition systems (ASR) applied to the public switched telephone network (PSTN). The state of the art reports that ASR systems that decode narrowband signals (NB) show lower performance systems that operate wideband signals (WB). In order to improve on PSTN ASR systems are used, for the development of an acoustic model (AM) as well as attributes of the speech signal extraction step, synthetic estimated WB signals from the NB enhancement by artificial extension bandwidth (ABWE). Results of word error rate (WER) are evaluated and verified the effectiveness of the proposed strategy.
\end{abstract}

\keywords{Automatic speech recognition, artificial bandwidth extension, speech enhancement.}

\selectlanguage{brazil}
\begin{abstract}
 Este trabalho apresenta uma nova estratégia para a implementação de sistemas de reconhecimento automático de fala (\textit{automatic speech recognition} - ASR) aplicados à rede pública de telefonia (\textit{public switched telephone network} - PSTN). O estado da arte reporta que sistemas de ASR que decodificam sinais de banda estreita (\textit{narrowband} - NB) apresentam desempenho inferior aos sistemas que operam com sinais de banda larga (\textit{wideband} - WB). Visando o aprimoramento de sistemas de ASR em PSTN, as etapas de extração de atributos do sinal da fala bem como a etapa de construção do modelo acústico (MA) são desenvolvidas baseadas em sinais sintéticos WB estimados a partir do realce de sinais NB usando extensão artificial de largura de banda (\textit{artificial bandwidrh extension} - ABWE). Resultados de taxa de erro de reconhecimento são avaliados e comprovam a eficácia da estratégia proposta.
\end{abstract}

\keywords{Reconhecimento automático de fala, extensão de largura de banda, realce do sinal de fala.}
]
% CONTRIBUIÇÃO
\selectlanguage{brazil}
\section{Introdução}
Atualmente o mercado de telefonia dispõe de diversos serviços interativos, tais como os serviços presentes em sistemas automatizados de \textit{help desk}, portais de voz, gerenciamento de diálogos em unidades de resposta audível (URA) e outros tipos de atendimento via \textit{call centers} \cite{Oliveira2012}, como apresentado na Fig.~\ref{ExemploURA}.

Tais serviços auxiliam o acesso de usuários da rede pública de telefonia (\textit{public switched telephone network} - PSTN) a informações via navegação em menus interativos. Esses menus podem ser acessados com a ajuda do teclado telefônico ou diretamente através de comandos de fala, em que o usuário é atendido por um assistente virtual controlado por reconhecimento automático de fala (\textit{automatic speech recognition} - ASR) aplicado à PSTN \cite{Nelson2011}.

Tendo em vista que os serviços comandados por fala são altamente dependentes do desempenho do ASR, as pesquisas sobre modelagem estatísticas desses sistemas continuam em franca evolução e se destacam como um tópico ativo em processamento digital de sinais \cite{Livescu2012}, \cite{Shaughnessy2013}, \cite{Bauer2014}.

\begin{figure}[h]
%\begin{minipage}{0.5\linewidth}
\center
\includegraphics[width=8cm]{figures/aplications.eps}
\caption{\label{ExemploURA}Exemplo de serviços disponíveis na rede telefônica.}
%\end{minipage}
\end{figure}

Resumidamente, um sistema típico de ASR é composto por duas etapas principais, o \textit{front-end} e o \textit{back-end}. A etapa de \textit{front-end} recebe o sinal de entrada e efetua a extração de vetores de observação contendo informações codificadas da fala. A etapa de \textit{back-end}, composta por um decodificador, dicionário fonético, modelo acústico e modelo de linguagem, é responsável pela decodificação dos vetores de observação e pelo processo de ``busca'' das informações linguísticas, e.g. fonemas e/ou palavras, contidas no sinal de fala \cite{HTKBook}, \cite{SpokenLanguage}.

Os sistemas de ASR aplicados a redes de telefonia podem ser implementados de acordo com três diferentes metodologias: reconhecimento de fala embarcado (\textit{embedded speech recognition} - ESR), que contêm as etapas de \textit{front-end} e \textit{back-end} integradas no aparelho telefônico; reconhecimento de fala distribuído (\textit{distributed speech recognition} - DSR), em que o \textit{front-end} é integrado no aparelho telefônico e o \textit{back-end} é localizado em um servidor externo; e o reconhecimento de fala em rede (\textit{network speech recognition} - NSR), em que tanto o \textit{front-end} quanto o \textit{back-end} são localizados em um servidor remoto e o aparelho telefônico apenas envia o sinal de fala para ser processado nesse servidor \cite{Dmitry2006}.

Visando a obtenção de melhores taxas de reconhecimento, sistemas de ASR desenvolvidos para \textit{desktops} utilizam sinais de fala em banda larga (\textit{wideband} - WB) amostrados geralmente a taxas maiores do que 16 kHz. Entretanto, sistemas aplicados à PSTN utilizam sinais de banda estreita (\textit{narowband} - NB) (apresentando largura de banda de 300 a 3400 Hz) amostrados a 8 kHz e devido às características inerentes ao canal telefônico da PSTN \cite{EnioSBrT2013}, além da perda de naturalidade e inteligibilidade, esses sinais quando comparados com sinais de fala WB com largura de banda entre 50 e 7000 Hz também apresentam perdas de desempenho em sistemas de ASR \cite{SpokenLanguage}.

Em \cite{Bauer2014}, \cite{EnioSBrT2013} e \cite{Bernd2007}, para contornar as limitações da comunicação em NB, a extensão artificial de largura de banda (\textit{artificial bandwidrh extension} - ABWE) é adotada como uma alternativa interessante capaz de proporcionar melhorias na qualidade dos sinais de fala, tornando-os mais próximos aos sinais WBs e, consequentemente, mais agradáveis aos usuários de PSTN.

Portanto, visando explorar os benefícios da ABWE, assim como os recursos computacionais em servidores remotos, neste trabalho, sugerimos a inclusão de um sistema de ABWE como uma etapa antecessora ao \textit{front-end} de um ASR utilizando a metodologia NSR. Nesse contexto, a metodologia NSR surge como uma alternativa interessante por apresentar como principal vantagem o escalonamento dos recursos computacionais disponíveis em um servidor \cite{Sunil2012}, tornando possível um processamento independente dos componentes de \textit{hardwares} dos aparelhos telefônicos.

Neste artigo, uma estratégia para sistemas de ASR com metodologia NSR é proposta e o desempenho do ASR com ABWE é discutido. A eficácia da estratégia implementada é verificada através de avaliações objetivas da taxa de erro de palavras (\textit{word error rate} - WER).

Este artigo está organizado como segue. Nas Seções~\ref{backgroundASR} e~\ref{backgroundABWE}, são apresentadas visões gerais dos sistemas de ASR e ABWE. Na Seção~\ref{FrameworkASRABWE}, é proposta a estratégia baseada na metodologia NSR e é descrito o desenvolvimento dos sistemas de ABWE e de ASR. Finalmente, as Seções~\ref{resultados} e~\ref{conclusao} apresentam, respectivamente, os resultados obtidos, e conclusões e comentários finais deste trabalho de pesquisa.

\section{Revisão/Fundamentos em reconhecimento automático de fala}
\label{backgroundASR}
O objetivo de um sistema de ASR é estimar satisfatoriamente as informações contidas em um sinal de fala. Geralmente o procedimento intermediário desse sistema é a conversão do sinal de fala em texto. Esta seção apresenta uma breve introdução a sistemas/aos fundamentos de ASR.

\subsection{Arquitetura}
Um sistema típico de ASR é composto por cinco blocos principais: \textit{front-end}, dicionário fonético, modelo acústico, modelo de linguagem e decodificador, sendo que os quatro últimos blocos compõem uma estrutura usualmente chamada \textit{back-end}, conforme indicado na Fig.~\ref{asr01}. 

\begin{figure}[h]
%\begin{minipage}{0.5\linewidth}
\center
\includegraphics[width=9cm]{figures/asr01.eps}
\caption{\label{asr01} Diagrama de blocos de um sistema de ASR.}
%\end{minipage}
\end{figure}

O \textit{front-end} extrai segmentos (\textit{frames}) a partir do sinal de fala e parametriza cada segmento em um vector $\textbf{x}$ de dimensão $L$. Supõe-se aqui que $T$ \textit{frames} são organizados em uma matriz $X$, de dimensão $L \times T$, para representar uma frase. O modelo de linguagem de um sistema de ASR fornece a probabilidade $p(\tau)$ de ocorrer uma sentença $\tau = [\omega_1, \dots, \omega_P]$ de $P$ palavras. Conceitualmente, o decodificador visa encontrar a sentença $\tau^{*}$ que maximiza a probabilidade a posteriori dada por
\begin{equation}
%$$\tau^{*} = \operatorname*{arg\,max}_{\tau}p(\tau|X)=\operatorname*{arg\,max}_{\tau}\frac{p(X|\tau)p(\tau)}{p(X)}$$
\tau^{*} = \operatorname*{arg\,max}_{\tau}p(\tau|X)=\operatorname*{arg\,max}_{\tau}\frac{p(X|\tau)p(\tau)}{p(X)}
\label{eqAsr01}
\end{equation}
onde $p(X|\tau)$ representa a verossimilhança acústica entre a matriz de observação $X$ e as palavras da sentença $\tau$, essa verossimilhança é determinada por um modelo acústico previamente treinado. Visto que $p(X)$ não depende de $\tau$, (\ref{eqAsr01}) é equivalente a 
\begin{equation}
%$$\tau^{*}=\operatorname*{arg\,max}_{\tau}p(X|\tau)p(\tau)$$
\tau^{*}=\operatorname*{arg\,max}_{\tau}p(X|\tau)p(\tau)
\label{eqAsr02}
\end{equation}

Devido ao grande número de possíveis frases, (\ref{eqAsr02}) não pode ser computada independentemente para cada frase candidata. Portanto, os sistemas de ASR geralmente usam estruturas de dados, tais como árvores lexicais hierárquicas, quebrando sentenças em palavras e palavras em unidades básicas como fones ou trifones \cite{SpokenLanguage}. O mapeamento das palavras para as unidades básicas e vice-versa é realizado através de um dicionário fonético. 

Em resumo, após o treinamento dos modelos, o ASR, na fase de teste, usa o \textit{front-end} para converter o sinal de entrada em atributos discriminativos e usa o \textit{back-end} para estimar a sentença $\tau$ mais apropriada ao sinal de entrada $X$. Dessa forma, quanto melhor a qualidade do sinal de fala, maior o desempenho esperado do ASR. Nesse contexto, sistemas de ASR desenvolvidos para \textit{desktops} que utilizam sinais de fala WB, com frequência de amostragem geralmente maior do que 16 kHz, $f_s \ge 16 \textrm{ kHz}$, apresentam em média desempenho $5\%$ supeior a sistemas que utilizam sinais amostrados a 8 kHz, como é o caso dos sinais provenientes da PSTN~\cite{SpokenLanguage}.

\subsection{Métrica de avaliação}
Na maioria das aplicações de ASR, a figura de mérito usada para avaliar tais sistemas é a taxa de erro de palavra (\textit{word error rate} - WER), definido como
\begin{equation}
\label{WER}
WER=\frac{D+R}{W}\times 100\%
\end{equation}
onde $W$ é o número de palavras na sequência de entrada, e $R$ e $D$ são o número de erros de substituição e deleção na sequência de palavra reconhecida, respectivamente, quando comparado com o de transcrição correta.

\subsection{Extração de Atributos}
Tendo em vista a obtenção de atributos ótimos discriminativos do sinal de fala, diversas alternativas para parametrizar as formas de onda desses sinais foram e continuam sendo desenvolidas. Dentre elas, a parametrização usando os coeficientes cepstrais da escala mel (\textit{mel frequency-cepstral coefficients-MFCCs}) mostra-se eficaz e é comumente usada no bloco de \textit{front-end} do ASR~\cite{SpokenLanguage}. Essa técnica de análise utiliza a escala mel, expressa por
\begin{equation}
m=M(f)=1125ln (1 + \frac{f}{700})
\end{equation}
onde $f$ representa os coeficientes de frequência na escala Hertz.

O procedimento de extração de atributos consiste em dividir o espectro do sinal em $B$ bandas com frequências centrais igualmente espaçadas na escala mel. Essas bandas de frequências são distribuidas através de bancos de filtros triangulares e, para cada banda, são computatos os valores do logarítmo da energia e a transformada discreta do cosseno (\textit{discrete cosine transform-DCT}). Os valores resultantes compõem os coeficientes MFCCs, como ilustrado no diagrama da Fig.~\ref{FigMfccScheme}. 
\begin{figure}[h]
\center
\includegraphics[width=8cm]{figures/mfcc-scheme.eps}
\caption{\label{FigMfccScheme}Diagrama ilustrativo da extração de atributos MFCC.}
\end{figure}

Dessa forma, a distribuição (adequada) dos componentes de frequência nas $B$ bandas é fundamental para a obtenção/o cálculo de ótimos atributos discriminativos. Portanto, a largura de banda do espectro do sinal é diretamente proporcional a qualidade dos atributos MFCCs. Então, por apresentarem uma maior faixa de frequência, sinais WB possuem atributos de maior resolução na análise MFCC quando comparados a atributos obtidos a partir de sinais NB~\cite{Bauer2014}. 

Entretanto, sinais NB podem ser realçados através de algorítmos de ABWE que possibilitam a estimação de novos componentes de frequência capazes de ampliar a largura de banda do espectro. Assim, os componentes de frequência, originais de NB e estimados de WB, podem ser redistribuídos eficientemente nos $B$ bancos de filtros triangulares (da análise MFCC). A Fig.~\ref{FigBancoFiltro} ilustra o processo de distribuição dos espectros NB e WB nos filtros triangulares correspondentes as $B$ bandas de frequência.
\begin{figure}[h]
\center
\includegraphics[width=8cm]{figures/BancoFiltros.eps}
\caption{\label{FigBancoFiltro}Distribuição dos espectros NB e WB nos $B$ bancos de filtros triangulares.}
\end{figure}

\begin{figure*}
  \centering
   \includegraphics[scale=0.85]{figures/Fig_1.eps}
  \centering
  \caption{\label{FigSistemaABWE}Diagrama de blocos do sistema ABWE.}
\end{figure*}
\begin{figure*}
  \centering
   \includegraphics[scale=0.25]{figures/nsr02.eps}
  \centering
  \caption{\label{FigSistemaNSR}Diagrama do ASR com ABWE em um sistema NSR.}
\end{figure*}


\section{Revisão/Fundamentos em extensão artificial de largura de banda}
\label{backgroundABWE}
O objetivo de um sistema de ABWE é realçar o sinal de fala NB, tornando-o mais agradável aos ouvintes e fazendo com que sua qualidade subjetiva se assemelhe à um sinal WB. Isso é possível através da estimação dos componentes de frequências acima de $3.4$ kHz. Assim, a idéia básica de um sistema de ABWE é sintetizar artificialmente componentes de alta frequência, convertendo um sinal NB em um sinal WB, isto é, estimando as propriedades acústicas pertinentes a WB~\cite{EnioSBrT2013},~\cite{Bauer2014}.

\subsection{Sistema de ABWE}
A Fig.~\ref{FigSistemaABWE} ilustra o diagrama de blocos do sistema de ABWE discutido em \cite{EnioSBrT2013} e aqui adotado. O diagrama tem como base uma estrutura de três estágios de processamento, descritos como segue:
\begin{enumerate}
 \item Estágio I. Estimação do sinal de excitação, $\hat{s}_{\UP}^{\exci}(n)$, através de predição linear (\textit{code-excited linear prediction} - CELP)~\cite{Bernd2007}.
 \item Estágio II. Filtragem do sinal de excitação resultante do primeiro estágio através dos envelopes temporal e espectral do trato-vocal estimados a partir de uma consulta a um conjunto de \textit{codebooks} baseados em classificação fonética.
 \item Estágio III. Cálculo de ganho e pós-processamento para a estimação do sinal WB.
\end{enumerate}
Os estágios que compõem o sistema ABWE são descritos com detalhes em ~\cite{EnioSBrT2013}.

\section{Estratégia NSR usando ASR com ABWE}
\label{FrameworkASRABWE}
No cenário de telefonia, sistemas NSR são adequados à utilização dos recusrsos computacionais de um servidor remoto. Assim, técnicas de processamento digital de sinais, tal como o realce da fala, podem ser melhor exploradas. Nesse contexto, este artigo propõe uma estratégia em que o sinal NB $s_{NB}$, fornecido pela PSTN, é realçado através de procedimentos de ABWE, gerando assim um sinal WB sintético $\hat{s}_{WB}$ na entrada do ASR, como ilustrado na Fig.~\ref{FigSistemaNSR}.
%\begin{figure*}
%  \centering
%   \includegraphics[scale=0.25]{figures/nsr02.eps}
%  \centering
%  \caption{\label{FigSistemaNSR}Diagrama do ASR com ABWE em um sistema NSR.}
%\end{figure*}
Portanto, o sistema NSR será composto pelos blocos de ABWE, seguido dos blocos do ASR: \textit{front-end} e \textit{back-end}.

\subsection{Construção de \textit{Codebooks} para ABWE}
No estágio II do sistema de ABWE, são estimados os envelopes temporais e espectrais de banda alta (UP) que caracterizam o trato vocal no processo de geração da fala. Esses envelopes são representados pelos seguintes vetores de parâmetros
\begin{equation}\label{eqParametros}
       \mathbf{t}_{n} = [t_n(1),\ldots,t_n(16)]\transp \\
\end{equation}
e
\begin{equation}
       \mathbf{f}_{\LSF,n} = [f_{\LSF,n}(1),\ldots,f_{\LSF,n}(19)]\transp
\end{equation}
onde o vetor $\mathbf{t}_n$ representa o envelope temporal contendo energias logarítmicas de $16$ subquadros ($1,25$ ms cada) \cite{Bernd2007} e o vetor $\mathbf{f}_{\LSF,n}$ contém os componentes LSFs que caracterizam o envelope espectral. 

Como ilustrado na Fig.~\ref{FigTreinamentoCB}, o processo de treinamento do sistema de ABWE consiste na construção do conjunto de \textit{codebooks} correspodentes aos envelopes do trato vocal no processo de geração da fala~\cite{EnioSBrT2013}.

\begin{figure}[h]
%\center
\hspace{-0.75cm}
\includegraphics[width=8cm]{figures/Fig_3.eps}
\caption{\label{FigTreinamentoCB}Etapa do processo de treinamento de \textit{codebooks}.}
\end{figure}

O processo de treinamento aqui utilizado considera as técnicas de \textit{codebooks} duais de banda estreita $X^{\NB}_{\CB}$ e de banda alta $Y^{\UP}_{\CB}$~\cite{unno05}, criados a partir do agrupamento dos vetores de parâmetros $\mathbf{x}^{NB}$ e $\mathbf{y}^{UP}$ em classes fonéticas dispostas de acordo com a Tabela~\ref{TebelaClasses}

\begin{table}[htb]
  \caption{Distribuição de classes fonéticas  para sinais de fala}\label{TebelaClasses}
  \begin{center}
  \begin{tabular}{|c|c|}\hline
  Classes &  Descrição\\\hline\hline
    $Cl_1$& Fricativas vozeadas alveolares\\\hline
    $Cl_2$& Fricativas vozeadas labiodentais\\\hline
    $Cl_3$& Fricativas vozeadas palatais\\\hline
    $Cl_4$& Demais fonemas vozeados\\\hline
    $Cl_5$& Fricativas não-vozeadas labiodentais\\\hline
    $Cl_6$& Fricativas não-vozeadas alveolares\\\hline
    $Cl_7$& Fricativas não-vozeadas palatais\\\hline
    $Cl_8$& Demais fonemas não-vozeados\\\hline
    $Cl_9$& Silêncio\\\hline
  \end{tabular}
  \end{center}
\end{table}

Deste modo, um treinamento supervisionado é realizado e o agrupamento dos vetores de parâmetros $\mathbf{x}^{NB}$ e $\mathbf{y}^{UP}$ torna-se mais discriminativo. Assim, cada \textit{codebook} é associado a uma classe fonética específica $\phi$, isto é, 
\begin{equation}
\begin{array}{r}
Y^{\UP}_{{\CB}_{\phi}}=E\{Y^{\UP} | \phi=Cl_i\}\\ % \, \in \, \Re^9 %\, \forall \, i=1 \ldots 9
X^{\NB}_{{\CB}_{\phi}}=E\{X^{\NB} | \phi=Cl_i\} 
\end{array}, \quad \forall i \in \, [1,9]
\end{equation}

\subsection{Estimação da Classe Fonética e dos Parâmetros do Trato Vocal para ABWE}
Para a estimação das classes fonéticas, $\phi \in \{Cl_1, \ldots, Cl_9\}$, o algoritmo de árvore de decisão J48 é utilizado \cite{bookweka}, \cite{algorithmJ48}. A cada \textit{frame} de 20 ms são extraídos vetores de observação contendo os seguintes parâmetros: os 10 primeiros coeficientes de auto-correlação, a taxa de cruzamento por zero, o índice de gradiente, a energia normalizada do frame, Kurtosis local e a centróide espectral, como apresentado em ~\cite{PJaxThesis}. A partir dos vetores de observação, a árvore de decisão é consultada e a classe fonética correspondente é obtida. A abordagem de agrupamento de classes similares (veja Tabela~\ref{TebelaClasses}) aumenta a robustez quanto a erros de classificação. A robustez é garantida porque mesmo havendo falhas de classificação, as classes fonéticas estimadas não estarão tão distantes de suas versões verdadeiras.

Supõe-se aqui que $\mathbf{q}^{\UP}$ representa os vetores que caracterizam o modelo do trato vocal de banda alta, $\mathbf{q}^{\UP} \supset [\mathbf{t}, \mathbf{f}_{\LSF}]$. Assim, $\mathbf{q}^{\UP}$ é organizado em uma matriz de \textit{codewords} $\mathbf{Q}(n | Y^{\UP}_{\CB_{\phi}})$ de acordo com as suas correspondentes classes fonéticas $\phi$. Dessa maneira, para a estimação de $\hat{\mathbf{q}}_{UP}$, uma vez determinada a classe $\phi$, do \textit{frame} do segmento de fala NB no instante $n$, as $K$ \textit{codewords} mais similares aos vetores $\mathbf{f}_{\LSF,n}$ e $\mathbf{t}_n$ do \textit{codebook} ${Y}^{\UP}_{{\CB}_{\phi}}$ são selecionadas via \textit{codebook dual} ${X}^{\NB}_{{\CB}_{\phi}}$, isto é,
\begin{equation}
\begin{array}{l}
\mathbf{Q}(n | Y^{\UP}_{\CB_{\phi}}) = \{\mathbf{q}^{\UP}_1(n|{X}^{\NB}_{{\CB}_{\phi}}),\mathbf{q}^{\UP}_2(n|{X}^{\NB}_{{\CB}_{\phi}}),..., \\
\mathbf{q}^{\UP}_{K}(n|{X}^{\NB}_{{\CB}_{\phi}})\}
\end{array}
\end{equation}
e os correspondentes vetores $\mathbf{f}_{\LSF,n}$ e $\mathbf{t}_n$ de banda alta são combinados linearmente com pesos $w$, calculados via distâncias euclidianas~\cite{unno05}, para cada \textit{codeword}. Assim,
\begin{equation}
\hat{\mathbf{q}}_{\UP}(n) = \sum_{m=1}^{K} w_m \cdot \mathbf{q}^{\UP}_{m}(n | X^{\NB}_{\CB_{\phi}}) \; \forall \; \mathbf{q}^{\UP}_m \supset [\mathbf{f}_{\LSF}, \mathbf{t}]
\end{equation}
onde $\mathbf{q}^{\UP}_{m}$ representa as \textit{codewords} constituídas pelos parâmetros $\mathbf{f}_{\LSF}$ e $\mathbf{t}$ de banda alta. Assim,
\begin{equation}
\begin{array}{l}
\hat{\mathbf{q}}^{\UP}(n) \supset [\hat{\mathbf{t}}_n, \hat{\mathbf{f}}_{\LSF,n}]\\
\hat{s}_{\UP}(n) = [\hat{s}_{\UP}^{\exci}(n) * \hat{\mathbf{t}}_n] * \hat{\mathbf{f}}_{\LSF,n} \\
%\hat{s}_{\UP}(n) = \hat{s}_{\UP}^{\exci}(n) * \hat{\mathbf{q}}_{\UP}(n) \\
\hat{s}_{\WB}(n) =  \hat{s}_{\UP}(n) + s_{\NB}(n).
\end{array}
\end{equation}

\subsection{Construção de Modelo Estatísticos para o ASR}
Em (\ref{eqAsr02}), $p(X|\tau)$ e $p(\tau)$ são determinados a partir dos modelos acústicos e de linguagem (MA e ML), respectivamente. A estimação de um modelo acústico satisfatório é considerada a etapa mais desafiadora do projeto de um sistema ASR. Nesse contexto, os procedimentos do ABWE discutidos na seção anterior são responsáveis pelo realce na matriz de observação $X$, migrando de um espaço de dados NB para WB. Assim, os atributos MFCCs analisados pelo \textit{front-end} contém informações espectrais mais discriminativas. Neste trabalho, utilizamos o software HTK~\cite{HTKBook} para construir modelos acústicos usando modelos escondidos de Markov (\textit{hidden Markov models} - HMMs), de acordo com as etapas descritas em~\cite{EnioSBC2005}. Para a cosntrução do modelo de linguagem, adotou-se a ferramenta MITLM~\cite{mitlm}.

Abaixo seguem alguns detalhes sobre as configurações utilizadas:
\begin{itemize}
\item Comprimento do \textit{fame} igual a $20$ ms com sobreposição de $10$ ms.
\item Coeficientes por \textit{fame} contendo valores de energia, 12 coeficientes cepstrais da escala mel e, suas primeiras e segundas derivadas.
\item MAs baseados em HMMs contínuas de 5 estados e topologia esquerda-direita, constituídas por modelos trifônicos \textit{cross-word} desenvolvidos/computados a partir de 38 monofones.
\item ML baseado em tri-gramas treinados com $1.534.980$ sentenças e utlizando a técnica de suavização de \textit{Kneser-Ney}~\cite{mitlm}.
\end{itemize}

\section{Resultados e Análise de Desempenho}
\label{resultados}
Para que seja possível a obtenção de taxas aceitáveis de precisão, o estado da arte de ASR, usando MAs baseados em HMMs, necessita de um banco de dados de áudio (\textit{corpora}) com grande variabilidade acústica, e os MLs necessitam de milhões de sentenças para uma modelagem precisa da língua em questão. Dessa forma, a disponibilidade de \textit{corpora} é um fator primordial para o desenvolvimento de modelos acústicos e de linguagem precisos. Um \textit{corpora} típico possui arquivos de voz com as suas transcrições associadas, grande quantidade de textos escritos e um dicionário fonético. Para atender tais requisitos, o desenvolvimento da etapa de ASR utiliza os \textit{corpora} de fala e texto disponibilizados em \cite{GrupoFalaBrasil} e \cite{YnogutiSBrT2008}.

Para análise de resultados, o corpora \textit{LapsBenchmark}~\cite{GrupoFalaBrasil} é adotado e os resultados das WERs, definada em (\ref{WER}), são utilizados na avalização de três diferentes sistemas: ASR com NB convencional da PSTN; ASR com WB; e NSR com ABWE e ASR. Os resultados obtidos com os dois primeiros sistemas, NB convencional da PSTN e  WB, são utilizados como referência para a avaliação de desempenho da estratégia NSR proposta neste artigo. 

A Tabela~\ref{resultado} apresenta o desempenho dos sistemas de referência (NB PSTN e WB) assim como o desempenho do NSR proposto, no qual os sinais WB são sintetizados através de ABWE.
\begin{table}[htb]
  \caption{Descrição dos testes realizados}\label{resultado}
  \begin{center}
  \begin{tabular}{|c|c|}\hline
\multicolumn{2}{|c|}{\textbf{Duração do corpora}}\\\hline
Treinamento & Teste \\\hline
4 horas & 54 minutos \\\hline\hline\hline
\multicolumn{2}{|c|}{\textbf{Desempenho do ASR}}\\\hline
  \textbf{Sistemas} & \textbf{WER} \\\hline
    NB PSTN& 30.69 \% \\\hline
    NSR: ABWE+ASR& 29.37 \% \\\hline
    WB Original& 27.77 \%\\\hline
  \end{tabular}
  \end{center}
\end{table}

Como apresentado na Tabela~\ref{resultado}, a estratégia NSR proposta neste trabalho apresenta um desempenho intermediário entre os sistemas NB PSTN e WB original, resultando em ganho relativo de aproximadamente $4,3$\% na WER quando comparado à aplicação direta de sinais NB convencionais na (rede) PSTN.

\section{Conclusões e Comentários Finais}
\label{conclusao}

Neste trabalho de pesquisa, uma estratégia de NSR utilizando ABWE foi apresentada. Essa estratégia implementa o realce do sinal NB (de entrada) e resulta em um sinal estimado WB capaz de fornecer (artificialmente) atributos cepstrais mais discriminativos ao ASR. O sinal WB estimado (de entrada) proporcionou maior riqueza espectral ao treinamento de modelos acústicos, quando comparado ao treinamento usando suas versões NB convencionais provenientes da PSTN(, resultando em MAs mais precisos). Resultados de avaliações objetivas apresentados na Tabela~\ref{resultado} ratificam tais afirmações e confirmam a eficácia da estimação dos novos componentes de frequência do sinal sintetizado WB $\hat{s}_{WB}$, bem como a distribuição propícia(adequada/apropriada/conveniente/oportuna) desses componentes nas $B$ bandas de frequência da análise MFCC.

%\subsection{Bibliografia}
%\label{sec:bibliografia}

%\section{Conclusões}
%Liste suas conclusões nesta seção, em vez de sim-plesmente relatar o que foi feito.

%\section*{Agradecimentos}
%Mencione aqui seus agradecimentos às agências de fomento e aos colaboradores do trabalho.

% BIBLIOGRAFIA
% Modern Speech Recognition Approaches with Case Studies
%Edited by S. Ramakrishnan, ISBN 978-953-51-0831-3, 326 pages, Publisher: InTech, Chapters published November 28, 2012 under CC BY 3.0 license
%DOI: 10.5772/2569 
\bibliography{cba01}
\end{document}